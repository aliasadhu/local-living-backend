{\rtf1\ansi\ansicpg1252\cocoartf2822
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 require('dotenv').config();\
const express = require('express');\
const cors = require('cors');\
const \{ GoogleGenerativeAI \} = require('@google/generative-ai');\
const SYSTEM_PROMPT = require('./systemPrompt');\
\
const app = express();\
app.use(cors());\
app.use(express.json());\
\
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);\
const model = genAI.getGenerativeModel(\{ model: "gemini-1.5-flash" \});\
\
app.get('/', (req, res) => res.send('Local Living Backend Active'));\
\
app.post('/diagnostic', async (req, res) => \{\
  try \{\
    const \{ history \} = req.body;\
    const conversation = history.map(turn => `$\{turn.role\}: $\{turn.text\}`).join('\\n');\
\
    const prompt = `\
      $\{SYSTEM_PROMPT\}\
      CURRENT CONVERSATION:\
      $\{conversation\}\
      YOUR RESPONSE (JSON ONLY):\
    `;\
\
    const result = await model.generateContent(prompt);\
    const text = result.response.text();\
    const cleanJson = text.replace(/```json/g, '').replace(/```/g, '').trim();\
    \
    res.json(JSON.parse(cleanJson));\
\
  \} catch (error) \{\
    console.error(error);\
    res.status(500).json(\{ error: "Failed" \});\
  \}\
\});\
\
const PORT = process.env.PORT || 3000;\
app.listen(PORT, () => console.log(`Server running on port $\{PORT\}`));}